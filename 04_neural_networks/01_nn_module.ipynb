{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4.1: Understanding nn.Module\n",
    "\n",
    "The foundation of all PyTorch neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is nn.Module?\n",
    "\n",
    "`nn.Module` is the base class for ALL neural network components in PyTorch.\n",
    "\n",
    "It provides:\n",
    "- Parameter management (automatic tracking of weights)\n",
    "- GPU/CPU movement (`.to(device)`)\n",
    "- Saving and loading models\n",
    "- Training/evaluation mode switching\n",
    "- And much more!\n",
    "\n",
    "**EVERY neural network you build will inherit from `nn.Module`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your first nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(nn.Module):\n",
    "    \"\"\"A simple linear transformation: y = x @ W + b\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features):\n",
    "        # Always call parent's __init__ first!\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create learnable parameters\n",
    "        # nn.Parameter tells PyTorch these should be trained\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define how input flows through the layer\n",
    "        return x @ self.weight + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance\n",
    "model = SimpleLinear(in_features=3, out_features=2)\n",
    "\n",
    "# Test it\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "output = model(x)  # This calls forward() automatically!\n",
    "\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Output: {output}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspecting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All parameters in the model:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: shape {param.shape}\")\n",
    "\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# Parameters have gradients tracked\n",
    "print(f\"\\nWeight requires_grad: {model.weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using built-in layers (preferred!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch provides pre-built layers - use these!\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "print(f\"Built-in Linear layer:\")\n",
    "print(f\"  Weight shape: {linear_layer.weight.shape}\")\n",
    "print(f\"  Bias shape: {linear_layer.bias.shape}\")\n",
    "\n",
    "# Same functionality, but optimized\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "output = linear_layer(x)\n",
    "print(f\"\\nInput: {x}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building a network with multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Data flows: input -> layer1 -> ReLU -> layer2 -> output\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)  # Activation function\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network: 10 inputs -> 5 hidden -> 2 outputs\n",
    "network = TwoLayerNetwork(10, 5, 2)\n",
    "\n",
    "# Test with random input\n",
    "x = torch.randn(10)\n",
    "output = network(x)\n",
    "\n",
    "print(f\"Network structure:\")\n",
    "print(network)\n",
    "print(f\"\\nInput shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "print(\"\\nAll parameters:\")\n",
    "for name, param in network.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training vs Evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Default mode - training: {network.training}\")\n",
    "\n",
    "# Switch to evaluation mode\n",
    "network.eval()\n",
    "print(f\"After .eval() - training: {network.training}\")\n",
    "\n",
    "# Switch back to training mode\n",
    "network.train()\n",
    "print(f\"After .train() - training: {network.training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does mode matter?**\n",
    "- Some layers behave differently during training vs evaluation\n",
    "- **Dropout**: active during training, disabled during evaluation\n",
    "- **BatchNorm**: uses batch stats in training, running stats in eval\n",
    "\n",
    "**ALWAYS use:**\n",
    "- `model.train()` before training\n",
    "- `model.eval()` before validation/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Device management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move entire model to device\n",
    "network = network.to(device)\n",
    "print(f\"Model moved to: {next(network.parameters()).device}\")\n",
    "\n",
    "# Input must also be on the same device!\n",
    "x = torch.randn(10).to(device)\n",
    "output = network(x)\n",
    "print(f\"Output device: {output.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** Model and data must be on the same device!\n",
    "\n",
    "Common pattern:\n",
    "```python\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MyModel().to(device)\n",
    "x = x.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### nn.Module Key Points\n",
    "\n",
    "1. **ALWAYS** inherit from `nn.Module`\n",
    "   ```python\n",
    "   class MyNet(nn.Module):\n",
    "   ```\n",
    "\n",
    "2. **ALWAYS** call `super().__init__()`\n",
    "   ```python\n",
    "   def __init__(self):\n",
    "       super().__init__()\n",
    "   ```\n",
    "\n",
    "3. Define layers in `__init__`\n",
    "   ```python\n",
    "   self.layer = nn.Linear(10, 5)\n",
    "   ```\n",
    "\n",
    "4. Define forward pass in `forward()`\n",
    "   ```python\n",
    "   def forward(self, x):\n",
    "       return self.layer(x)\n",
    "   ```\n",
    "\n",
    "5. Call model directly (not `model.forward()`)\n",
    "   ```python\n",
    "   output = model(x)  # Correct\n",
    "   output = model.forward(x)  # Works but not recommended\n",
    "   ```\n",
    "\n",
    "6. Use `.train()` and `.eval()` appropriately\n",
    "\n",
    "7. Use `.to(device)` for GPU/CPU management\n",
    "\n",
    "**PARAMETERS ARE TRACKED AUTOMATICALLY** when you use `nn.Module` and `nn.Parameter`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Next:** Open `02_layers.ipynb` to learn about different layer types!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
