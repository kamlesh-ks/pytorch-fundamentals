{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2.3: Combining Tensors\n",
    "\n",
    "Learn how to combine multiple tensors together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. torch.cat() - Concatenate along existing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "b = torch.tensor([[5, 6],\n",
    "                  [7, 8]])\n",
    "\n",
    "print(f\"Tensor a:\\n{a}\")\n",
    "print(f\"\\nTensor b:\\n{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along dimension 0 (rows)\n",
    "cat_dim0 = torch.cat([a, b], dim=0)\n",
    "print(f\"Concatenate dim=0 (stack vertically):\\n{cat_dim0}\")\n",
    "print(f\"Shape: {cat_dim0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along dimension 1 (columns)\n",
    "cat_dim1 = torch.cat([a, b], dim=1)\n",
    "print(f\"Concatenate dim=1 (stack horizontally):\\n{cat_dim1}\")\n",
    "print(f\"Shape: {cat_dim1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can concatenate more than 2 tensors\n",
    "c = torch.tensor([[9, 10],\n",
    "                  [11, 12]])\n",
    "cat_three = torch.cat([a, b, c], dim=0)\n",
    "print(f\"Concatenate three tensors:\\n{cat_three}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. torch.stack() - Stack along NEW dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "z = torch.tensor([7, 8, 9])\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"z: {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack creates a NEW dimension\n",
    "stacked_0 = torch.stack([x, y, z], dim=0)\n",
    "print(f\"Stack dim=0:\\n{stacked_0}\")\n",
    "print(f\"Shape: {stacked_0.shape}\")  # (3, 3)\n",
    "\n",
    "stacked_1 = torch.stack([x, y, z], dim=1)\n",
    "print(f\"\\nStack dim=1:\\n{stacked_1}\")\n",
    "print(f\"Shape: {stacked_1.shape}\")  # (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between cat and stack:\n",
    "\n",
    "- **cat**: joins along EXISTING dimension (no new dimension)\n",
    "- **stack**: creates a NEW dimension\n",
    "\n",
    "Example with 1D tensors `[1,2,3]` and `[4,5,6]`:\n",
    "- `cat(dim=0)` -> `[1,2,3,4,5,6]` shape: `(6,)`\n",
    "- `stack(dim=0)` -> `[[1,2,3],[4,5,6]]` shape: `(2, 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical example: Creating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating 4 individual images (grayscale, 28x28)\n",
    "image1 = torch.randn(1, 28, 28)  # [channels, height, width]\n",
    "image2 = torch.randn(1, 28, 28)\n",
    "image3 = torch.randn(1, 28, 28)\n",
    "image4 = torch.randn(1, 28, 28)\n",
    "\n",
    "# Stack to create a batch\n",
    "batch = torch.stack([image1, image2, image3, image4], dim=0)\n",
    "print(f\"Single image shape: {image1.shape}\")\n",
    "print(f\"Batch shape: {batch.shape}\")  # [batch, channels, height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. torch.chunk() and torch.split() - Divide tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor to split\n",
    "data = torch.arange(12).reshape(4, 3)\n",
    "print(f\"Original data:\\n{data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk: split into equal parts\n",
    "chunks = torch.chunk(data, chunks=2, dim=0)\n",
    "print(f\"Chunk into 2 parts (dim=0):\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"  Chunk {i}:\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split: split by specific sizes\n",
    "splits = torch.split(data, split_size_or_sections=[1, 3], dim=0)\n",
    "print(f\"Split [1, 3] (dim=0):\")\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"  Split {i}:\\n{split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convenience functions: hstack, vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# hstack: horizontal stack (along columns)\n",
    "print(f\"hstack: {torch.hstack([a, b])}\")\n",
    "\n",
    "# vstack: vertical stack (along rows)\n",
    "print(f\"vstack:\\n{torch.vstack([a, b])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2D tensors\n",
    "m1 = torch.tensor([[1, 2], [3, 4]])\n",
    "m2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"Matrix m1:\\n{m1}\")\n",
    "print(f\"Matrix m2:\\n{m2}\")\n",
    "print(f\"\\nhstack:\\n{torch.hstack([m1, m2])}\")\n",
    "print(f\"\\nvstack:\\n{torch.vstack([m1, m2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Broadcasting (Automatic size matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting automatically expands dimensions\n",
    "a = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "b = torch.tensor([10, 20, 30, 40])  # Shape: (4,)\n",
    "\n",
    "print(f\"a (shape {a.shape}):\\n{a}\")\n",
    "print(f\"b (shape {b.shape}): {b}\")\n",
    "\n",
    "# PyTorch broadcasts automatically!\n",
    "result = a + b  # (3, 1) + (4,) -> (3, 4)\n",
    "print(f\"\\na + b (shape {result.shape}):\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting rules:\n",
    "\n",
    "1. Align shapes from the right\n",
    "2. Dimensions must be equal or one of them must be 1\n",
    "3. Missing dimensions are treated as 1\n",
    "\n",
    "**Example:** `(3, 1) + (4,)`\n",
    "- Step 1: Align -> `(3, 1)` and `(1, 4)`\n",
    "- Step 2: Expand -> `(3, 4)` and `(3, 4)`\n",
    "- Step 3: Add element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Combining\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `torch.cat([a, b], dim)` | Join along existing dimension |\n",
    "| `torch.stack([a, b], dim)` | Join along NEW dimension |\n",
    "| `torch.hstack([a, b])` | Horizontal stack |\n",
    "| `torch.vstack([a, b])` | Vertical stack |\n",
    "\n",
    "### Splitting\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `torch.chunk(x, n, dim)` | Split into n equal parts |\n",
    "| `torch.split(x, sizes, dim)` | Split by specific sizes |\n",
    "\n",
    "### Broadcasting\n",
    "- Automatic size matching for operations\n",
    "- Shapes aligned from right\n",
    "- Size-1 dims are expanded\n",
    "\n",
    "### Key Insight\n",
    "- Use **STACK** to create batches from individual samples\n",
    "- Use **CAT** to combine batches into larger batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Next:** Move to Module 3 to learn about autograd!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
