{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2.2: Reshaping Tensors\n",
    "\n",
    "Learn how to change tensor dimensions - crucial for neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. reshape() - The most common operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D tensor\n",
    "original = torch.arange(12)\n",
    "print(f\"Original (shape {original.shape}): {original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to different dimensions\n",
    "reshaped_3x4 = original.reshape(3, 4)\n",
    "print(f\"Reshaped to 3x4:\\n{reshaped_3x4}\")\n",
    "\n",
    "reshaped_4x3 = original.reshape(4, 3)\n",
    "print(f\"\\nReshaped to 4x3:\\n{reshaped_4x3}\")\n",
    "\n",
    "reshaped_2x2x3 = original.reshape(2, 2, 3)\n",
    "print(f\"\\nReshaped to 2x2x3:\\n{reshaped_2x2x3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using -1 to auto-calculate one dimension\n",
    "auto_rows = original.reshape(-1, 4)  # -1 means \"figure it out\"\n",
    "print(f\"Reshape (-1, 4) -> {auto_rows.shape}:\\n{auto_rows}\")\n",
    "\n",
    "auto_cols = original.reshape(3, -1)\n",
    "print(f\"\\nReshape (3, -1) -> {auto_cols.shape}:\\n{auto_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. view() - Similar to reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = torch.arange(12)\n",
    "\n",
    "# view() works like reshape() but requires contiguous memory\n",
    "viewed = original.view(3, 4)\n",
    "print(f\"View (3, 4):\\n{viewed}\")\n",
    "\n",
    "# view() shares memory with original!\n",
    "viewed[0, 0] = 999\n",
    "print(f\"\\nAfter modifying view, original: {original}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `view()` and `reshape()` are similar, but:\n",
    "- `view()` requires contiguous memory, shares storage\n",
    "- `reshape()` may copy data if needed\n",
    "- For beginners, `reshape()` is safer to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. flatten() and ravel() - Make 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "print(f\"Matrix:\\n{matrix}\")\n",
    "\n",
    "# Flatten to 1D\n",
    "flattened = matrix.flatten()\n",
    "print(f\"\\nFlattened: {flattened}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten specific dimensions\n",
    "tensor_3d = torch.arange(24).reshape(2, 3, 4)\n",
    "print(f\"3D tensor shape: {tensor_3d.shape}\")\n",
    "\n",
    "flat_all = tensor_3d.flatten()\n",
    "print(f\"Flatten all: shape {flat_all.shape}\")\n",
    "\n",
    "flat_partial = tensor_3d.flatten(start_dim=1)  # Keep first dim\n",
    "print(f\"Flatten from dim 1: shape {flat_partial.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. squeeze() and unsqueeze() - Add/remove dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze() removes dimensions of size 1\n",
    "x = torch.zeros(1, 3, 1, 4, 1)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Squeezed shape: {x.squeeze().shape}\")\n",
    "\n",
    "# Remove specific dimension\n",
    "print(f\"Squeeze dim 0: {x.squeeze(0).shape}\")\n",
    "print(f\"Squeeze dim 2: {x.squeeze(2).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsqueeze() adds a dimension of size 1\n",
    "y = torch.tensor([1, 2, 3])\n",
    "print(f\"Original y: {y}, shape: {y.shape}\")\n",
    "\n",
    "print(f\"Unsqueeze dim 0: {y.unsqueeze(0)}, shape: {y.unsqueeze(0).shape}\")\n",
    "print(f\"Unsqueeze dim 1: {y.unsqueeze(1)}, shape: {y.unsqueeze(1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical use: adding batch dimension\n",
    "single_image = torch.randn(3, 224, 224)  # [channels, height, width]\n",
    "batched = single_image.unsqueeze(0)      # [batch, channels, height, width]\n",
    "print(f\"Single image: {single_image.shape}\")\n",
    "print(f\"With batch dim: {batched.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. transpose() and permute() - Swap dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose() swaps two dimensions\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "print(f\"Original (shape {matrix.shape}):\\n{matrix}\")\n",
    "\n",
    "transposed = matrix.transpose(0, 1)  # Swap rows and columns\n",
    "print(f\"\\nTransposed (shape {transposed.shape}):\\n{transposed}\")\n",
    "\n",
    "# .T is shorthand for 2D transpose\n",
    "print(f\"\\nUsing .T:\\n{matrix.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute() rearranges all dimensions\n",
    "tensor_3d = torch.randn(2, 3, 4)\n",
    "print(f\"3D tensor shape: {tensor_3d.shape}\")\n",
    "\n",
    "permuted = tensor_3d.permute(2, 0, 1)  # Rearrange to (4, 2, 3)\n",
    "print(f\"Permuted (2,0,1) shape: {permuted.shape}\")\n",
    "\n",
    "# Common use: image format conversion\n",
    "# PyTorch uses: [batch, channels, height, width]\n",
    "# Some libraries use: [batch, height, width, channels]\n",
    "pytorch_format = torch.randn(1, 3, 224, 224)  # [B, C, H, W]\n",
    "other_format = pytorch_format.permute(0, 2, 3, 1)  # [B, H, W, C]\n",
    "print(f\"\\nPyTorch format: {pytorch_format.shape}\")\n",
    "print(f\"Other format: {other_format.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. expand() and repeat() - Duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "print(f\"Original (shape {x.shape}):\\n{x}\")\n",
    "\n",
    "# expand() broadcasts without copying (memory efficient)\n",
    "expanded = x.expand(3, 4)\n",
    "print(f\"\\nExpanded to (3, 4):\\n{expanded}\")\n",
    "\n",
    "# repeat() actually copies the data\n",
    "repeated = x.repeat(1, 4)  # Repeat 1 time in dim 0, 4 times in dim 1\n",
    "print(f\"\\nRepeated (1, 4):\\n{repeated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Common reshaping patterns in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Patterns:\n",
    "\n",
    "**Pattern 1: Flattening for fully connected layer**\n",
    "- Input: `[batch, channels, height, width]`\n",
    "- Output: `[batch, features]`\n",
    "- Code: `x.flatten(start_dim=1)` or `x.view(batch_size, -1)`\n",
    "\n",
    "**Pattern 2: Adding batch dimension**\n",
    "- Input: `[channels, height, width]`\n",
    "- Output: `[1, channels, height, width]`\n",
    "- Code: `x.unsqueeze(0)`\n",
    "\n",
    "**Pattern 3: Removing batch dimension**\n",
    "- Input: `[1, channels, height, width]`\n",
    "- Output: `[channels, height, width]`\n",
    "- Code: `x.squeeze(0)`\n",
    "\n",
    "**Pattern 4: Channel manipulation**\n",
    "- `[batch, height, width, channels]` -> `[batch, channels, height, width]`\n",
    "- Code: `x.permute(0, 3, 1, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Flattening for fully connected layer\n",
    "batch_size = 4\n",
    "feature_maps = torch.randn(batch_size, 32, 7, 7)  # After conv layers\n",
    "print(f\"Feature maps shape: {feature_maps.shape}\")\n",
    "\n",
    "flattened = feature_maps.flatten(start_dim=1)\n",
    "print(f\"Flattened for FC: {flattened.shape}\")\n",
    "print(f\"Each sample has {flattened.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Reshape Operations\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `.reshape(shape)` | Change shape (may copy) |\n",
    "| `.view(shape)` | Change shape (no copy, needs contiguous) |\n",
    "| `.flatten()` | Make 1D |\n",
    "| `.squeeze()` | Remove size-1 dimensions |\n",
    "| `.unsqueeze(dim)` | Add size-1 dimension |\n",
    "| `.transpose(d1, d2)` | Swap two dimensions |\n",
    "| `.permute(dims)` | Reorder all dimensions |\n",
    "| `.expand(size)` | Broadcast (no copy) |\n",
    "| `.repeat(times)` | Duplicate (copies) |\n",
    "\n",
    "### Key Tips\n",
    "- Use `-1` in reshape to auto-calculate one dimension\n",
    "- Total elements must remain the same after reshape\n",
    "- `flatten(start_dim=1)` is common before FC layers\n",
    "- `unsqueeze(0)` adds batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Next:** Open `03_combining_tensors.ipynb` to learn about combining tensors!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
